#Importando as Libs
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Carrega e exibe as 5 primeiras linhas
human_data = pd.read_table('data/human_data.txt')
human_data.head()

# Carrega e exibe as 5 primeiras linhas
chimp_data = pd.read_table('data/chimp_data.txt')
dog_data = pd.read_table('data/dog_data.txt')
chimp_data.head()
dog_data.head()

# função para converter strings de sequência em palavras k-mer, tamanho padrão = 6 (palavras hexâmeras)
def getKmers(sequence, size=6):
    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]

# Transforma sequências em palavras 
human_data['words'] = human_data.apply(lambda x: getKmers(x['sequence']), axis=1)
human_data = human_data.drop('sequence', axis=1)
chimp_data['words'] = chimp_data.apply(lambda x: getKmers(x['sequence']), axis=1)
chimp_data = chimp_data.drop('sequence', axis=1)
dog_data['words'] = dog_data.apply(lambda x: getKmers(x['sequence']), axis=1)
dog_data = dog_data.drop('sequence', axis=1)

human_data.head()

# Converte listas de palavras em "human_data" em strings e extrai rótulos (y_data).
human_texts = list(human_data['words'])
for item in range(len(human_texts)):
    human_texts[item] = ' '.join(human_texts[item])
y_data = human_data.iloc[:, 0].values
print(human_texts[2])

y_data

# Processa dados de chimpanzés e cães semelhantes aos dados humanos (lista de palavras para string, extração de rótulos).
chimp_texts = list(chimp_data['words'])
for item in range(len(chimp_texts)):
    chimp_texts[item] = ' '.join(chimp_texts[item])
y_chimp = chimp_data.iloc[:, 0].values                       

dog_texts = list(dog_data['words'])
for item in range(len(dog_texts)):
    dog_texts[item] = ' '.join(dog_texts[item])
y_dog = dog_data.iloc[:, 0].values   

# Criando o modelo Bag of Words usando CountVectorizer()
#Isso é equivalente à contagem de k-mer
# O tamanho de n gramas de 4 foi previamente determinado por testes
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(ngram_range=(4,4))
X = cv.fit_transform(human_texts)
X_chimp = cv.transform(chimp_texts)
X_dog = cv.transform(dog_texts)
print(X.shape)
print(X_chimp.shape)
print(X_dog.shape)

human_data['class'].value_counts().sort_index().plot.bar()

# Divide os dados em conjuntos de treinamento e teste (divisão de 80%/20%, random_state=42 para reprodutibilidade).
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y_data, 
                                                    test_size = 0.20, 
                                                    random_state=42)
print(X_train.shape)
print(X_test.shape)  

# Treina um classificador Multinomial Naive Bayes com um valor alfa pré-determinado (0,1).
from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB(alpha=0.1)
classifier.fit(X_train, y_train)

# Gera previsões para os dados de teste usando o classificador treinado.
y_pred = classifier.predict(X_test)

# Avalia o desempenho do modelo usando matriz de confusão, exatidão, precisão, recall e pontuação F1.
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
print("Confusion matrix\n")
print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))
def get_metrics(y_test, y_predicted):
    accuracy = accuracy_score(y_test, y_predicted)
    precision = precision_score(y_test, y_predicted, average='weighted')
    recall = recall_score(y_test, y_predicted, average='weighted')
    f1 = f1_score(y_test, y_predicted, average='weighted')
    return accuracy, precision, recall, f1
accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)
print("accuracy = %.3f \nprecision = %.3f \nrecall = %.3f \nf1 = %.3f" % (accuracy, precision, recall, f1))
